import streamlit as st
import pandas as pd
import numpy as np
from datasets_search import load_openml_dataset, load_huggingface_dataset
from preprocessing import preprocess_data
from models import train_and_evaluate
from utils import (
    plot_correlation_matrix, plot_feature_distributions, plot_boxplots_numeric_vs_target,
    plot_roc_curve, plot_confusion_matrix, plot_feature_importance, plot_residuals,
    plot_prediction_probabilities, plot_actual_vs_predicted
)

st.set_page_config(page_title="ML Playground", layout="wide")

st.title("ðŸš€ Machine Learning Playground")
st.markdown("**Advanced ML with Comprehensive EDA & Model Evaluation**")

# Dataset selection
st.sidebar.header("ðŸ“‚ Dataset Options")
dataset_source = st.sidebar.radio("Choose dataset source:", ["Upload CSV", "OpenML", "Hugging Face"])

df = None

if dataset_source == "Upload CSV":
    uploaded_file = st.sidebar.file_uploader("Upload your CSV file", type=["csv"])
    if uploaded_file is not None:
        df = pd.read_csv(uploaded_file)

elif dataset_source == "OpenML":
    openml_id = st.sidebar.text_input("Enter OpenML dataset ID", "61")
    st.sidebar.caption("ðŸ‘‰ Example: 61 = Iris dataset")
    if st.sidebar.button("Load from OpenML"):
        df = load_openml_dataset(openml_id)

elif dataset_source == "Hugging Face":
    hf_name = st.sidebar.text_input("Enter Hugging Face dataset name", "imdb")
    st.sidebar.caption("ðŸ‘‰ Example: imdb = sentiment analysis dataset")
    if st.sidebar.button("Load from Hugging Face"):
        df = load_huggingface_dataset(hf_name)

if df is not None:
    st.write("### ðŸ“Š Dataset Preview")
    st.dataframe(df.head(10))
    st.write(f"**Shape:** {df.shape[0]} rows Ã— {df.shape[1]} columns")
    
    # Dataset info
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Total Features", len(df.columns))
    with col2:
        st.metric("Numeric Features", len(df.select_dtypes(include=[np.number]).columns))
    with col3:
        st.metric("Categorical Features", len(df.select_dtypes(include=['object', 'category']).columns))

    target_col = st.selectbox("ðŸŽ¯ Select target column", df.columns)
    
    if target_col:
        # Determine problem type
        unique_targets = df[target_col].nunique()
        is_classification = unique_targets < 20
        
        st.info(f"**Problem Type:** {'Classification' if is_classification else 'Regression'} ({unique_targets} unique values)")
        
        # Preprocessing
        with st.spinner("ðŸ”„ Preprocessing data..."):
            X_train, X_test, y_train, y_test = preprocess_data(df, target_col)
        
        # Model Training
        with st.spinner("ðŸ¤– Training models..."):
            results, trained_models = train_and_evaluate(X_train, X_test, y_train, y_test)
        
        # Create tabs for different sections
        tab1, tab2, tab3, tab4 = st.tabs(["ðŸ“Š EDA", "ðŸ¤– Model Results", "ðŸ“ˆ Predictions", "â„¹ï¸ Dataset Info"])
        
        with tab1:
            st.header("ðŸ“Š Exploratory Data Analysis (EDA)")
            
            # Correlation Matrix
            st.subheader("ðŸ“Š Correlation Heatmap")
            corr_plot = plot_correlation_matrix(df)
            if corr_plot:
                st.pyplot(corr_plot)
            else:
                st.warning("Not enough numeric features for correlation analysis")
            
            # Feature Distributions
            st.subheader("ðŸ“ˆ Feature Distributions")
            dist_plot = plot_feature_distributions(df)
            if dist_plot:
                st.pyplot(dist_plot)
            else:
                st.warning("No features available for distribution analysis")
            
            # Boxplots for numeric vs target
            if is_classification:
                st.subheader("ðŸ“‰ Numeric Features vs Target")
                box_plot = plot_boxplots_numeric_vs_target(df, target_col)
                if box_plot:
                    st.pyplot(box_plot)
                else:
                    st.warning("Target column is not numeric or no numeric features available")
        
        with tab2:
            st.header("ðŸ¤– Model Results & Evaluation")
            
            # Model Performance Metrics
            st.subheader("ðŸ“Š Performance Metrics")
            for model_name, metrics in results.items():
                with st.expander(f"**{model_name}**"):
                    if is_classification:
                        st.metric("Accuracy", f"{metrics['accuracy']:.3f}")
                    else:
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("MSE", f"{metrics['MSE']:.3f}")
                        with col2:
                            st.metric("RMSE", f"{metrics['RMSE']:.3f}")
            
            # Model Evaluation Plots
            st.subheader("âœ… Model Evaluation Visualizations")
            
            for model_name, metrics in results.items():
                st.write(f"#### {model_name}")
                
                if is_classification:
                    # ROC Curve
                    if 'probabilities' in metrics:
                        roc_plot = plot_roc_curve(y_test, metrics['probabilities'][:, 1], model_name)
                        if roc_plot:
                            st.pyplot(roc_plot)
                    
                    # Confusion Matrix
                    conf_plot = plot_confusion_matrix(y_test, metrics['predictions'], model_name)
                    if conf_plot:
                        st.pyplot(conf_plot)
                    
                    # Feature Importance (for tree-based models)
                    if hasattr(metrics['model'], 'feature_importances_'):
                        feat_imp_plot = plot_feature_importance(
                            metrics['model'], X_train.columns, model_name
                        )
                        if feat_imp_plot:
                            st.pyplot(feat_imp_plot)
                
                else:
                    # Residual Plot for regression
                    resid_plot = plot_residuals(y_test, metrics['predictions'], model_name)
                    if resid_plot:
                        st.pyplot(resid_plot)
                    
                    # Feature Importance (for tree-based models)
                    if hasattr(metrics['model'], 'feature_importances_'):
                        feat_imp_plot = plot_feature_importance(
                            metrics['model'], X_train.columns, model_name
                        )
                        if feat_imp_plot:
                            st.pyplot(feat_imp_plot)
        
        with tab3:
            st.header("ðŸ“ˆ Predictions")
            
            # Model Selection for Predictions
            model_names = list(trained_models.keys())
            selected_model_name = st.selectbox("Select model for predictions:", model_names)
            selected_model = trained_models[selected_model_name]
            
            # Prediction Type Selection
            pred_type = st.radio("Choose prediction type:", ["Manual Input", "Batch Upload"])
            
            if pred_type == "Manual Input":
                st.subheader("ðŸ”® Manual Predictions")
                st.write("Enter feature values for prediction:")
                
                # Create input form
                input_data = {}
                feature_cols = X_train.columns
                
                cols = st.columns(min(3, len(feature_cols)))
                for i, col in enumerate(feature_cols):
                    with cols[i % len(cols)]:
                        if X_train[col].dtype in ['int64', 'float64']:
                            # Numeric input
                            min_val = float(X_train[col].min())
                            max_val = float(X_train[col].max())
                            input_data[col] = st.number_input(
                                f"{col}", 
                                min_value=min_val, 
                                max_value=max_val, 
                                value=float(X_train[col].median())
                            )
                        else:
                            # Categorical input
                            unique_vals = X_train[col].unique()
                            input_data[col] = st.selectbox(f"{col}", unique_vals)
                
                if st.button("ðŸ”® Make Prediction"):
                    # Convert to DataFrame
                    input_df = pd.DataFrame([input_data])
                    
                    # Make prediction
                    if is_classification:
                        pred = selected_model.predict(input_df)[0]
                        pred_proba = selected_model.predict_proba(input_df)[0]
                        
                        st.success(f"**Prediction:** {pred}")
                        st.write("**Class Probabilities:**")
                        classes = selected_model.classes_
                        for i, prob in enumerate(pred_proba):
                            st.write(f"  {classes[i]}: {prob:.3f}")
                    else:
                        pred = selected_model.predict(input_df)[0]
                        st.success(f"**Prediction:** {pred:.3f}")
            
            else:  # Batch Upload
                st.subheader("ðŸ“ Batch Predictions")
                uploaded_pred_file = st.file_uploader("Upload CSV for batch predictions", type=["csv"])
                
                if uploaded_pred_file is not None:
                    pred_df = pd.read_csv(uploaded_pred_file)
                    st.write("**Uploaded Data Preview:**")
                    st.dataframe(pred_df.head())
                    
                    if st.button("ðŸ”® Make Batch Predictions"):
                        # Ensure same features as training data
                        missing_cols = set(X_train.columns) - set(pred_df.columns)
                        if missing_cols:
                            st.error(f"Missing columns: {missing_cols}")
                        else:
                            # Make predictions
                            pred_df_subset = pred_df[X_train.columns]
                            predictions = selected_model.predict(pred_df_subset)
                            
                            # Add predictions to dataframe
                            result_df = pred_df.copy()
                            result_df['Prediction'] = predictions
                            
                            if is_classification:
                                probabilities = selected_model.predict_proba(pred_df_subset)
                                for i, class_name in enumerate(selected_model.classes_):
                                    result_df[f'Probability_{class_name}'] = probabilities[:, i]
                            
                            st.write("**Prediction Results:**")
                            st.dataframe(result_df)
                            
                            # Download results
                            csv = result_df.to_csv(index=False)
                            st.download_button(
                                label="ðŸ“¥ Download Predictions",
                                data=csv,
                                file_name="predictions.csv",
                                mime="text/csv"
                            )
            
            # Prediction Visualizations
            st.subheader("ðŸ“Š Prediction Visualizations")
            
            if is_classification and 'probabilities' in results[selected_model_name]:
                # Probability Distribution
                prob_plot = plot_prediction_probabilities(
                    results[selected_model_name]['probabilities'], selected_model_name
                )
                if prob_plot:
                    st.pyplot(prob_plot)
                
                # ROC Curve for predictions
                roc_plot = plot_roc_curve(
                    y_test, results[selected_model_name]['probabilities'][:, 1], selected_model_name
                )
                if roc_plot:
                    st.pyplot(roc_plot)
            
            else:
                # Actual vs Predicted for regression
                actual_pred_plot = plot_actual_vs_predicted(
                    y_test, results[selected_model_name]['predictions'], selected_model_name
                )
                if actual_pred_plot:
                    st.pyplot(actual_pred_plot)
        
        with tab4:
            st.header("â„¹ï¸ Dataset Information")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("ðŸ“Š Data Types")
                dtype_df = pd.DataFrame({
                    'Column': df.columns,
                    'Data Type': df.dtypes,
                    'Non-Null Count': df.count(),
                    'Null Count': df.isnull().sum()
                })
                st.dataframe(dtype_df)
            
            with col2:
                st.subheader("ðŸ“ˆ Statistical Summary")
                st.dataframe(df.describe())
            
            st.subheader("ðŸ” Missing Values")
            missing_data = df.isnull().sum()
            missing_data = missing_data[missing_data > 0]
            if len(missing_data) > 0:
                st.bar_chart(missing_data)
            else:
                st.success("âœ… No missing values found!")
            
            st.subheader("ðŸŽ¯ Target Variable Analysis")
            st.write(f"**Target Column:** {target_col}")
            st.write(f"**Unique Values:** {df[target_col].nunique()}")
            st.write(f"**Data Type:** {df[target_col].dtype}")
            
            if is_classification:
                st.write("**Class Distribution:**")
                class_counts = df[target_col].value_counts()
                st.bar_chart(class_counts)
            else:
                st.write("**Target Statistics:**")
                st.write(df[target_col].describe())
